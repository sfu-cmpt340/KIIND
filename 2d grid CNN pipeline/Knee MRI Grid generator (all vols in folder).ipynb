{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5033a4be-65ab-4d73-9ee5-843b3f9fe6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: progressbar\n",
      "  Building wheel for progressbar (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=40edbc3a35de536b1fc1d68ef0d2e13b8ead7eb48ca7080612cc84ff52ba6136\n",
      "  Stored in directory: /Users/danielsloseris/Library/Caches/pip/wheels/8d/bb/b2/5353b966ac6f3c5e1000629a9a5f6aed41794487f551e32efc\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "##############comments#############\n",
    "#22/11/2023 11:47pm - saves grid images in a folder in reverse order \n",
    "!pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c3d8d1d-f28b-4fc6-8e76-7f0e88d95c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "\n",
    "def pil_grid(images, max_horiz=np.iinfo(int).max):\n",
    "    n_images = len(images)\n",
    "    n_horiz = min(n_images, max_horiz)\n",
    "    h_sizes, v_sizes = [0] * n_horiz, [0] * (n_images // n_horiz)\n",
    "    for i, im in enumerate(images):\n",
    "        h, v = i % n_horiz, i // n_horiz\n",
    "        h_sizes[h] = max(h_sizes[h], im.size[0])\n",
    "        v_sizes[v] = max(v_sizes[v], im.size[1])\n",
    "    h_sizes, v_sizes = np.cumsum([0] + h_sizes), np.cumsum([0] + v_sizes)\n",
    "    im_grid = Image.new('RGB', (h_sizes[-1], v_sizes[-1]), color='white')\n",
    "    for i, im in enumerate(images):\n",
    "        im_grid.paste(im, (h_sizes[i % n_horiz], v_sizes[i // n_horiz]))\n",
    "    return im_grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff43662c-e17c-4ed4-9ff9-be075236d35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data will be saved in:\n",
      "/Users/danielsloseris/Desktop/CMPT 340/Project/ImageClassification/MRNet-v1.0/train/sagittal_grid_images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Get all .npy file paths in a folder\n",
    "folder_path_images = 'MRNet-v1.0/train/sagittal'  # Update this with the path to your folder containing .npy files\n",
    "file_names = os.listdir(folder_path_images)\n",
    "file_paths = [os.path.join(folder_path_images, file_name) for file_name in file_names if file_name.endswith('.npy')]\n",
    "\n",
    "\n",
    "#Step 2 get current path and create new folder to save data in current path\n",
    "path = os.path.join(os.getcwd(), folder_path_images + '_grid_images')\n",
    "\n",
    "\n",
    "if os.path.isdir(path):\n",
    "    print(\"Folder: {\", os.path.basename(path), \"} already exists! Create a new folder name!\")\n",
    "else:\n",
    "    os.makedirs(path)\n",
    "    print(\"Data will be saved in:\")\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a5476fb-771e-49d1-a112-6a9261e807b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================DONE=======================\n",
      "Num grid Images created: 1130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Step 3: iterate over all .npy volumes in folder and generate grids of the slices laid out in a square\n",
    "\n",
    "count = 0\n",
    "for file_path in file_paths:\n",
    "    \n",
    "    #load volume\n",
    "    vol = np.load(file_path)\n",
    "    nSlices = np.size(vol,0)#num of slices in image\n",
    "    # print(\"num Slices:\",nSlices)\n",
    "    \n",
    "    volName = os.path.basename(file_path)\n",
    "    end = volName.find('.')\n",
    "    volName = volName[:end]  \n",
    "\n",
    "    # print(f\"File Name: {os.path.basename(file_path)}\")\n",
    "         \n",
    "    #add all slices into a single array \"images\", a PIL, Image object\n",
    "    slices= []\n",
    "    for i in range(nSlices):\n",
    "        image = Image.fromarray(vol[i,:,:])\n",
    "        # image = image.resize((128,128), 1)# can resize images to make smaller and reduce compute\n",
    "        slices.append(image)\n",
    "        \n",
    "        \n",
    "    gridEdgeSize = int(np.sqrt(nSlices)) #will round down to smallest smaller edge size for a squrae grid\n",
    "    nSlicesInGrid = gridEdgeSize**2 #number of slices to include in grid to ensure square\n",
    "    nSlices_Excluded = nSlices-nSlicesInGrid #number of slices excluded to ensure perfect square\n",
    "    \n",
    "    \n",
    "    \n",
    "    #divide the number of exluded slices into 2 to remove from beginning and end, \n",
    "    #to hopefully capture more information in middle slices\n",
    "    nSlices_Excluded_first_half = nSlices_Excluded//2\n",
    "    nSlices_Excluded_second_half = nSlices_Excluded-nSlices_Excluded_first_half\n",
    "    start = nSlices_Excluded_first_half\n",
    "    end = nSlices-nSlices_Excluded_second_half\n",
    "\n",
    "    # print(\"File Name: {} | total slices: {}, slices included: {}\".format(os.path.basename(file_path),nSlices,len(slices[start:end]) ))\n",
    "    \n",
    "    # print(\"num Slices Included\",len(slices[start:end]))\n",
    "    #generate grid of images (slices) for one particular .npy file, ignoring the last few\n",
    "    # grid = pil_grid(slices[:nSlicesInGrid],gridEdgeSize) #removes all excluded slices from the end\n",
    "    grid = pil_grid(slices[start:end],gridEdgeSize) #removes half of excluded slices from beginning and half from end\n",
    "    \n",
    "    #depending on the values at position intVolName on the csvs (info stored in dataArray) place image in correct folder\n",
    "    grid.save(os.path.join(path, 'grid{}.jpeg'.format(volName)))\n",
    "    count = count+1\n",
    "\n",
    "print(\"\\n===================DONE=======================\")\n",
    "print(\"Num grid Images created:\",count)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36508ae9-14bf-4288-a8f9-529b9eb5ba6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
